{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets\n",
    "\n",
    "train = datasets.MNIST(\"\", train=True, download=True,\n",
    "                       transform= transforms.Compose([transforms.ToTensor()]))\n",
    "test = datasets.MNIST(\"\", train=False, download=True,\n",
    "                       transform= transforms.Compose([transforms.ToTensor()]))\n",
    "\n",
    "trainset = torch.utils.data.DataLoader(train, batch_size=(10), shuffle=True)\n",
    "testset = torch.utils.data.DataLoader(test, batch_size=(10), shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "fc1\n",
    "\n",
    "fc: fully connected\n",
    "\n",
    "1: level 1\n",
    "\n",
    "Linear parameters requires, input and output\n",
    "\n",
    "input = usually a matrix\n",
    "output = usually an array -> Linear"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc1): Linear(in_features=784, out_features=64, bias=True)\n",
      "  (fc2): Linear(in_features=64, out_features=64, bias=True)\n",
      "  (fc3): Linear(in_features=64, out_features=64, bias=True)\n",
      "  (fc4): Linear(in_features=64, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(28*28, 64)\n",
    "        self.fc2 = nn.Linear(64, 64)  # second layer\n",
    "        self.fc3 = nn.Linear(64, 64)\n",
    "        self.fc4 = nn.Linear(64, 10)  # output layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "net = Net()\n",
    "print(net)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "F.relu() => Rectifier activate function\n",
    "\n",
    "the final layer doesn't need the activate function"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "X = torch.rand((28,28))\n",
    "X = X.view(-1, 28*28)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "we generated a tensor as a matrix.\n",
    "\n",
    "So we need to flat it before pass it to the network\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[-2.2693, -2.4393, -2.1875, -2.3677, -2.1864, -2.4391, -2.3096, -2.3795,\n         -2.2290, -2.2596]], grad_fn=<LogSoftmaxBackward>)"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = net(X)\n",
    "\n",
    "output"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0123, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3166, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0077, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.Adam(net.parameters(),lr = 0.001)\n",
    "\n",
    "EPOCHS = 3\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    for data in trainset:\n",
    "        X, y = data\n",
    "        net.zero_grad()\n",
    "        output = net(X.view(-1, 28*28))\n",
    "        loss = F.nll_loss(output, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(loss)\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.978\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total =  0\n",
    "with torch.no_grad():\n",
    "    for data in trainset:\n",
    "        X, y = data\n",
    "        output = net(X.view(-1,784))\n",
    "        for idx, i in enumerate(output):\n",
    "            if torch.argmax(i) == y[idx]:\n",
    "                correct +=1\n",
    "            total += 1\n",
    "\n",
    "print(\"Accuracy: \", round(correct/total, 3))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(X[2].view(28,28))\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(8)\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    output = torch.argmax(net(X[2].view(-1,784)))\n",
    "print(output)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}